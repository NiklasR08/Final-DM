---
title: "Final Group Project Data Mining"
knit: (function(input_file, encoding) {
  out_dir = 'docs';
  rmarkdown::render(input_file,
  encoding=encoding,
  output_file=file.path(dirname(input_file), out_dir, 'index.html'))}
author: "Adriana Barlafante, Guglielmo Bonifazi, Niklas Rengelshausen"
date: "1/11/2022"
output: html_document
editor_options: 
  markdown: 
    wrap: 100
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# World Happiness Report

**Task:** The aim is to study the characteristics of society described in the data sets: what factors affect well-being and how do they relate to each other? The two bases provided should be combined.

## Introduction

For our analysis of the data set we divided our work into multiple steps. To have an overview of our steps please have a look at the Index. The data analysis is made with two data set which we later combined after having a first look at both data sets and the kaggle page to better understand the data.

**Origin of the data:** 
World Happiness (WH): <https://www.kaggle.com/unsdsn/world-happiness> 
Human Freedom Index (HFI): <https://www.kaggle.com/gsutters/the-human-freedom-index>

In addition we had a look at the used the [following book](https://www.cato.org/sites/cato.org/files/2021-01/human-freedom-index-2016.pdf) to better understand the data set of the Human Freedom Index. The data set contains over 120 different variables and to understand these variables the book helped with some descriptions (see p. 185 ff.)

### Index

-- 1. Filtering of the Data Set and Imputation of Values

-- 2. Descriptive Statistics

-- 3. Principal Component Analysis (PCA)

-- 4. Cluster Analysis

-- 5. Multidimensional Scaling

-- 6. Perceptual Maps

-- 7. Possible Extension (NEW HEADLINE NEEDED)

```{r include=FALSE, warning=FALSE}
## PLEASE LOAD LIBRARY HERE AND RERUN CODE CHUNK
library(data.table)
library(tidyverse)
library(VIM)
library(mice)
library(GGally)
library(factoextra)
library(FactoMineR)
library(cluster)
```

## 1. Filtering of the Data Set and Imputation of Missing Values
We will first load the data set and have a first look to better understand the data. Later we will reduce the information of the data set to only relevant columns and in the end we will impute missing values and merge the two data sets into one.

### 1.1 Loading Data Sets and First Look

```{r}
wh = read.csv("2016.csv")         # World Happiness
hfi = read.csv("hfi_cc_2018.csv") # Human Freedom Index
```

**World Happiness:**

```{r include=TRUE, echo=FALSE}
wh
```

This data set contains information regarding the happiness of different countries. Next to an index which ranks each country, the data set also has a happiness score on which the happiness rank is based. Additionally the data set contains columns such as GDP or Health Life Expectancy. All the observations are from 2016. 
The columns following the happiness score estimate the extent to which each of six factors – economic production, social support, life expectancy, freedom, absence of corruption, and generosity – contribute to making life evaluations higher in each country than they are in Dystopia, a hypothetical country that has values equal to the world’s lowest national averages for each of the six factors. They have no impact on the total score reported for each country, but they do explain why some countries rank higher than others. 
GDP per Capita, Family, Life Expectancy, Freedom, Generosity, Trust Government Corruption describe the extent to which these factors contribute in evaluating the happiness in each country. The Dystopia Residual metric actually is the Dystopia Happiness Score(1.85) + the Residual value or the unexplained value for each country
([see kaggle](https://www.kaggle.com/unsdsn/world-happiness))


For a further insights please have a look at the descriptive statistics.

**Human Freedom Index:**

```{r}
hfi
```

For the second data set we can see that it contains 1458 observations and 123 variables. The data set contains a huge number of variables. Nonetheless, they are organized hierarchically so we do not need them all. As previously stated, the data set deals with the human freedom index.

This variable has been computed considering two factors:personal freedom and economic freedom. We can observe that human freedom (hf) is the simple average of economic freedom (ec) and personal freedom (pf).

```{r}
all.equal(hfi$hf_score, (hfi$ef_score + hfi$pf_score)/2)
```

More in detail, economic freedom and personal freedom have been computed using other factors.

```{r}
#Indexes of variables used to compute economic freedom
ec=c(70,81,86,99,118)
colnames(hfi)[ec]
```

```{r}
#Indexes of variables used to compute personal freedom
pf=c(8,22,26,32,44,52,61)
colnames(hfi)[pf]
```

Moreover, even those variables have been computed using other factors. For instance we can observe the composition of pf_rol as the following:

```{r}
colnames(hfi[5:8])
```

This means that pf_rol is calculated by using pf_rol_procedural, pf_rol_civil and pf_rol_criminal. The same holds for other variables as well. Going deeper we can see that some of those variables can be further decomposed:

```{r}
colnames(hfi)[9:22]
```

For instance we can observe that pf_ss can be derived from pf_ss_homicide, disappearances and women. But both disappearances and women can be further divided as you can see.

From this quick analysis is clear that a lot of information is redundant or extremely specific so that we can drop some of the variables we do not need for our analysis.

```{r}
reduced_hfi <- hfi[, c(3, 2, 1, 4, pf, ec, 62, 63, 119, 120, 121, 122, 123)]
dim(reduced_hfi)
```
Column 5-11:      Variables that compute pf 
Column 12-13:     pf_score and pf_rank 
Column 14-18:     Variables that compute ef 
Column 19-10:     ef_score and ef_rank 
Column 21-23:     hf_score, rank and quartile

We were able to reduce the data set from over 120 different variables to a total of 23 variables that we can use for our analysis. Note that this data set still contains data from different years beside 2016.

```{r}
reduced_hfi16 = reduced_hfi[reduced_hfi$year == 2016, ]
dim(reduced_hfi16)
```
Reducing the observations to the ones of 2016, we are able to combine the obtained results with the first data set.

### 1.2 Imputation of missing Values

During our first analysis we noticed that the Human Freedom Index data set is missing some values and the World Happiness index is not missing any values. To have a better analysis we therefore decided to complete the missing information of the data set.

**First Look at Variables:**

```{r}
summary(reduced_hfi16)
missing_hfi <- reduced_hfi16[,5:16]
```

From this first look we can see that there are some values missing for the variables that compute personal freedom and economical freedom. We will now use some descriptive plots to better understand how much data is missing.

**Descriptive statistics with missing values:**

```{r}
aggr(missing_hfi, 
     numbers = T, #to display the numbers on top of the bars
     prop = c(T, F) # prop is a logical indicating whether the proportion of 
     )              # missing values and combinations should be used rather than the total amount
```

The plot shows on the one hand how often a variable is missing and on the other hand in which combinations. We can see that for pf_religion less than one percent of the values is missing and for pf_association more than 15% of the values are missing. Additionally we can see on the second plot that only in one case is pf_religion and pf_association missing, in 25 cases only pf_association is missing and in most of the cases (136) no variable is missing!

**Imputation of Missing Variables:** 
For the imputation of the missing values we will use the mice function under the following assumptions: We assume that the missing data are missing at random (MAR) which means that the probability that a value is missing depends only on the observed values and can be predicted using them. It imputes data on a variable by variable basis by specifying an imputation model per variable.

We will use the predictive mean matching method (pmm) because the missing data of our data set contains purely numeric variables.

```{r echo=FALSE}
imputed_hfi16 <- mice(reduced_hfi16, m = 5, maxit = 50, seed = 500)
summary(imputed_hfi16)
```

```{r}
complete_hfi <- complete(imputed_hfi16, 1)
```

The data set now has no more missing values. Remember that for pf_association more than 15% of the values were missing in the before imputing them. To see if there is a big difference between the two data sets we will now compare the distribution of values between the values of pf_association with imputed values and without imputed values.

```{r}
par(mfrow = c(2, 2))
boxplot(missing_hfi$pf_association, main = "Without Imputed Values", ylim = c(0, 12))
boxplot(complete_hfi$pf_association ,main = "With Imputed Values", ylim = c(0, 12))
hist(missing_hfi$pf_association, main = "Without Imputed Values", xlab = "Score pf_association")
hist(complete_hfi$pf_association ,main = "With Imputed Values",  xlab = "Score pf_association")
par(mfrow = c(1,1))
```

The box plot's look almost the same for both data sets and we can also see that in the distribution not much changed. The histogram "With Imputed Values" might look a different than the other one but that is due to the fact that it contains more values (values that were missing before). From the box plot we can see that the median and quantiles are about the same. So for our further analysis we can use the complete data set. We could also have a look at the distribution of pf_religion because we had one missing value there, but given that it is only one value we will probably not see a lot of change between the two data sets.

### 1.3 Merging of the Two Data Sets 
We will now merge the two data sets into one data set with which we can work.

```{r}
#declare as data table
wh <- data.table(wh)
complete_hfi <- data.table(complete_hfi)

# renaming of column to merge both data sets
colnames(wh)[1] = "countries" 

#merge data sets to one
dt <- merge(wh, complete_hfi, by = "countries")

#convert to data table
dt <- data.table(dt)
View(dt) 
dim(dt)

```

```{r}
#Create file
out_path <- 'data_merged.csv' ## the file will be stored in the current working directory
fwrite(dt, out_path)

dt <- fread(out_path) 
```


### 1.4 Summary:
In the first step of our analysis we were able to understand the two data sets and do some filtering. This included exploring the variables of the data sets and removing redundant information that we will not need for our further analysis. We saw that some of the variables were missing values. We analyzed the missing values and imputed them with the help of a predictive mean matching method using the mice package. Finally, we merged both data sets into one data set for the further data analysis. The analysis will now continue with some descriptive statistics of the data sets.

## 2. Descriptive Statistics (Niklas)
This part includes a quick data preparation where we will choose the relevant variables for our descriptive data analysis. Furthermore, we will perform some univariate and multivariate statistical analysis and look at the correlation between variables. The goal is to derive some first insights into what could drive well being.

### 2.1 Data Preparation

For the descriptive analysis of the data we will focus just on a part of the data and reduce the data set to the most important data points. 
From the first data set (World Happiness) we will focus on the following variables: countries, Region, Happiness.Score, Economy..GDP.per.Capita., Family, Health..Life.Expectancy., Freedom, Trust..Government.Corruption., Generosity. The Happiness.Score in the end is the closest score that tells us about the well being of individuals in a country. Additionally, the last six of these scores have the potential to deliver some explanation for the Happiness.Score (we will call them potential influence variables).
From the second data set (Human Freedom Index) we will focus on the following three variables: pf_score, ef_score and hf_score. The reason for that is that these variables are already a calculation of the other variables given in our data set. So, considering only them, we reduce the number of variables and do not use redundant information.
```{r}
#dropping information that is not needed
dt_ds <- dt[, c(1,14,2,4,7,8,9,10,11,12,29,31,33)]
dt_ds$Region = as.factor(dt_ds$Region)
dim(dt_ds) #data table descriptive statistics
```


### 2.2 Univariate Analysis
We will now do some univariate analysis for the most important variables to better understand the data that is presented to us. 

**Region**
As a start we can have a look at the different regions our countries come from. Overall we have 137 countries in our data set.
```{r}
table(dt_ds$Region)
```
As you can see the majority of our countries come from Africa (48 total), Europe (43 total) and from the region of Latin America and Caribbean (22 total).

**Happiness.Score**
As stated earlier, happiness score is important to us because it reflects the well being of a country.

```{r}
hist(dt_ds$Happiness.Score, main = "Histogram Happiness Score", xlim = c(0, 10), xlab = "Happiness Score")
```
```{r}
summary(dt_ds$Happiness.Score)
```
From the histogram and the summary statistics we can see that the average and median happiness is around 5,4. The data also does not show any outliers. Given that the score can be anywhere between a 10 (best possible) and a 0 (worst possible) the distribution is not strongly skewed.

**Potential Influence Variables:**
```{r}
par(mfrow = c(2, 3))
hist(dt_ds$Economy..GDP.per.Capita., main = "GDP per Capita", xlab = "Weight of GDP per Capita", xlim = c(0, 2), ylim = c(0, 40))
hist(dt_ds$Family, main = "Family", xlab = "Weight of Family", xlim = c(0, 2), ylim = c(0, 40))
hist(dt_ds$Health..Life.Expectancy., main = "Health & Life Expectancy", xlab = "Weight of Health & Life Expectancy", xlim = c(0, 2), ylim = c(0, 40))
hist(dt_ds$Freedom, main = "Freedom", xlab = "Weight of Freedom", xlim = c(0, 1), ylim = c(0, 40))
hist(dt_ds$Trust..Government.Corruption., main = "Corruption", xlab = "Weight of Corruption", xlim = c(0, 1), ylim = c(0, 40))
hist(dt_ds$Generosity, main = "Generosity", xlab = "Weight of Generosity", xlim = c(0, 1), ylim = c(0, 40))

par(mfrow = c(1,1))
```

```{r}
summary(dt_ds[, 5:10])
```
From the histograms we can see that Family, Life Expectancy and Freedom are left-skewed while Corruption and Generosity are more right-skewed. Given that the score measures the weight that a variable has for the calculation of the happiness index makes a direct interpretation not easy. For example, having a high GDP.per.capita value doesn't necessarily mean having a high GDP, rather that GDP contributes a lot to the Happiness Score. Likewise, for example, a country has a low score on Corruption this does not mean that corruption is low, it only means that Corruption does not contribute a lot to the Happiness Score. (according to the author of the data). Therefore, for that country it is not a relevant characteristic in determinig the well being. 
If we look at the scale of the histograms we can see that GDP per Capita, Family and Health & Life Expectancy were weighted higher on average, while Freedom, Corruption and Generosity were weighted lower on average.

**Personal Freedom, Economic Freedom and Human Freedom**
```{r}
par(mfrow = c(1, 3))
hist(dt_ds$pf_score, main = "Personal Freedom", xlab = "Score of Personal Freedom", xlim = c(0,10), ylim = c(0, 35))
hist(dt_ds$ef_score, main = "Economic Freedom", xlab = "Score of Economic Freedom", xlim = c(0,10), ylim = c(0, 35))
hist(dt_ds$hf_score, main = "Human Freedom", xlab = "Score of Human Freedom", xlim = c(0,10), ylim = c(0, 35))

par(mfrow = c(1, 1))
```
```{r}
summary(dt_ds[,11:13])
```
The distribution of all three graphs is left-skewed. Based on the median we see no big difference between the economic freedom and personal freedom scores. The distribution on the other hand is slightly different for the two.
The human freedom score is the average on the pf_score and ef_score which we can see here (average pf_score + average ef_score = average hf_score).


### 2.3 Bi- and Multivariate Analysis
In the following Analysis we will try to figure out if there is a relationship between the variables. We will start to have an overview of the potential relationships and then focus on some specific ones for our analysis.


#### 2.3.1 Overall Look
We will use the GGally package to display all combinations for the first data set and look at interesting combinations between the variables
```{r}
ggpairs(dt_ds, 
        columns = c("Happiness.Score", "Economy..GDP.per.Capita.", "Family", "Health..Life.Expectancy.", "Freedom", "Trust..Government.Corruption.", "Generosity", "pf_score", "ef_score", "hf_score"), 
        lower = list(continuous = wrap("smooth" , alpha = 0.8, size = 0.01)), 
        upper = list(continuous = wrap("cor", size = 2.8))
        ) +
  theme_grey(base_size =  6)
```
In a first step we want to look at the Happiness.Score relationships with the other variables as it is directly related to the well being of a country. In a second step we will look at relationship between the variables that could have an effect on the happiness.
Remember that we saw in our univariate analysis that the following variables had on average a higher weight for the calculation of the Happiness Score: GDP, Family and Health & Life Expectancy while Freedom, Corruption and Generosity were weighted lower on average.
Now what we can see from the plots is, that for the variables with a higher weight there seems to be a positive correlation between the weight a variable received and the Happiness.Score for that country. On the other hand there seems to be low to no correlation between the Happiness.Score and the other variables that were weighted lower on average. For the variables pf_score, ef_score and hf_score the correlation is somewhere between 0.47 and 0.56. As stated earlier the hf_score is an average between of the ef_score and pf_score so we would only rather only look at the relationship between hf_score and Happiness.Score. 
Interestingly the data shows no negative correlation at all. From this point of view one could say that a higher happiness score is almost always related to a higher score in another variable. For example a higher score (weight) in GDP per Capita shows a higher Happiness.Score. As a consequence we can claim that the more a country consider relevant one of the themes expressed by the variables, the more it is happy. Furthermore, countries that believe GDP, Family and Health & Life Expectancy are important factors, are the happiest in general.
The following relationships are interesting in the first part and we will try to have a closer look at them:
-- Happiness.Score and GDP
-- Happiness.Score and Family
-- Happiness.Score and Health & Life Expectancy
-- Happiness.Score and hf_score

For the second part we will have a look at the relationships between the variables that could affect the Happiness.Score of a country. We can see there is a strong relationship between Health & Life expectancy and GDP we should take a closer look at. Additionally we can see a positive relationship between Family and GDP we should have a closer look at. For the other variables there seems to be little to no correlation and/or do not seem interesting for us at this point for a further analysis.
Interestingly we do not see a strong correlation between the personal freedom score (pf_score) and Freedom and between the economic freedom score (ef_score) and GDP. These two do seem like they should be related so we will also take a closer look at these two variables.
The following relationships are interesting to us in the second part and we will try to have a closer look at them:
-- GDP and Family
-- GDP and Health & Life Expectancy
-- pf_score and Freedom
-- ef_score and GDP
-- ef_score and pf_score

#### 2.3.2 Happiness Score Related Relationships
In the following we will also often use region to try to understand if there are patterns that are valid among states of the same region.

**Happiness.Score and GDP:**
```{r}
ggplot(data = dt_ds, aes(x = Economy..GDP.per.Capita., y = Happiness.Score)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Weight of GDP per Capita", main = "Happiness Score and GDP")
```
We already now from the previous analysis that there is a positive correlation between the happiness score and the weight we put on GDP to calculate the happiness score. It looks like that in countries where the happiness score is higher, they tend to put more weight on GDP per Capita than in countries where the happiness is lower. This could be a sign of wealth and happiness. 

What could now be interesting is to look if we can find some pattern for that positive correlation. To do so we will have a look at the different regions where the countries come from. As you can see the dots seem to be ordered in a way. To have a better look at the data we will split it according to the region to see if there is still a positive correlation.

```{r}
ggplot(data = dt_ds, aes(x = Economy..GDP.per.Capita., y = Happiness.Score)) + 
  geom_point() +
  facet_wrap(~ Region) +
  stat_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Weight of GDP per Capita")
```
Notice that, after splitting the data, we can see that it appears to be a pattern for the different regions. For some regions we do not have enough data points to make a statement but for most regions there still seems to be a positive correlation between the happiness score and the weight of the GDP. The only exception is Southern Asia region, where countries happiness score is more or less the same regardless of GDP weight.



Furthermore, we can have a look at the difference between developed countries and developing countries. Countries from the following regions are developed countries: Western Europe, North America, Australia and New Zealand, Central and Eastern Europe. While countries from these regions are mostly developing countries: Asia, Africa and Latin America and Caribbean.

```{r}
#creating a column to determine which country is from a developed region and which is not
dt_ds_c <- dt_ds %>%
  mutate(Development_Status = 
    ifelse(Region == "Australia and New Zealand", "Developed", 
           ifelse(Region == "Central and Eastern Europe", "Developed", 
                  ifelse(Region == "North America", "Developed", 
                         ifelse(Region == "Western Europe", "Developed", "Developing")))))


ggplot(dt_ds_c, aes(x = Economy..GDP.per.Capita., y = Happiness.Score)) +
  geom_point(aes(color = Region), main = "Developed Countries vs Developing Countries") +
  geom_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Weight of GDP per Capita") +
  facet_wrap(~Development_Status) 
```
For both types of countries we can again see a positive relationship between GDP and Happiness.Score. While for developed countries the Happiness.Score is often higher we can see that this strongly depends on its region. However, the relationship between GDP importance and Happiness score is further evident in developed countries (it is almost perfectly linear and with a greater slope) rather than in developing countries. Therefore, giving more weight to GDP is expected to increases the happiness score more in developed countries than in developing ones.

%%%%%%%%%%%%%%%%%%%%%%%%%
Summary (CLEAN IT): even though a positive correlation is recorded in both groups, in developed countries Happiness Score and GDP importance relationship is stronger. In particular it is almost perfectly linear and with a greater slope. As a consequence, trying to explain Happiness with GDP importance, we can claim that: increasing the weight of GDP is going to increase happiness more in developed countries than in developing ones. This pattern is quite reasonable, indeed developed countries have higher GDP, so that valuing it more will make them happier.
%%%%%%%%%%%%%%%%%%%%%%%%%%%

Another interesting point is that developed countries (countries from regions such as Western Europe, North America, Australia and New Zealand, Central and Eastern Europe) put on average more weight on GDP when calculating the happiness index than developing countries (countries from other regions). 
```{r}
dt_ds_c[, mean(Economy..GDP.per.Capita.), by = Development_Status]
```

To extend that analysis we can have a look at relationship between Happiness.Score and region to better understand if richer countries are really happier than poorer countries.

```{r}
ggplot(data = dt_ds, aes(Happiness.Score)) +
  geom_boxplot() +
  facet_wrap(~Region)
```
As one can see from this box plot, richer countries tend to have a higher happiness score than poorer countries. The plots show that countries from the rich regions like Australia and New Zealand, North America and Western Europe have higher happiness scores that countries that come from poor regions like Sub-Saharan Africa. This could be a reason why the GDP weight is positive correlated with happiness and richer countries tend to values GDP more.

**Happiness.Score and Family:**
```{r}
ggplot(data = dt_ds, aes(x = Family, y = Happiness.Score)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Weight of Family", main = "Happiness Score and GDP")
```
Next to the positive correlation we are again able to to see a similar distribution of the regions as for GDP. We can have a closer look at the different regions by themselves.


```{r}
ggplot(data = dt_ds, aes(x = Family, y = Happiness.Score)) + 
  geom_point() +
  facet_wrap(~ Region) +
  stat_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Weight of Family")
```
Also here (apart from Southern Asia) we see that a high Happiness.Score usually also means that the country puts more weight on Family for the calculation of their Happiness.Score. 

**Happiness.Score and Health & Life Expectancy:**
```{r}
ggplot(data = dt_ds, aes(x = Health..Life.Expectancy., y = Happiness.Score)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Weight of Health & Life Expectancy", main = "Happiness Score and Health & Life Expectancy")
```
```{r}
ggplot(data = dt_ds, aes(x = Health..Life.Expectancy., y = Happiness.Score)) + 
  geom_point() +
  facet_wrap(~ Region) +
  stat_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Weight of GDP per Capita")
```
Once again we do not see any exciting deviations from the pattern we presented you earlier.
The findings are not surprising and strengthen our first assumption that countries with a high happiness score also put more weight on the potential influencing variables. In other words high scores on variables such as Family, Health & Life Expectancy and GDP usually result in a high score in happiness of the overall country.

**Happiness.Score and hf_score:**
```{r}
ggplot(data = dt_ds, aes(x = hf_score, y = Happiness.Score)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "Happiness Score", x = "Human Freedom Score", main = "Happiness Score and GDP")
```
Interestingly we see that the data is a lot more spread for this case than for this case than for the other variables. The correlation as shown earlier is not very high. As you can see in some cases a low human freedom score is still related to a high happiness score (mostly for countries from Latin America and Caribbean).

**Conclusion**
From this Analysis we can conclude the following three points:
1. For some variables there seems to be little to no correlation with the happiness score. In the case for Generosity, for example, the scatter plot shows no interesting behavior on how it influences the happiness score of a country.
2. We were able to observe that countries with a high happiness score also put more weight on the potential influencing variables. In other words high scores on variables such as Family, Health & Life Expectancy and GDP usually result in a high score in happiness of the overall country.
3. The human freedom score and happiness score show a not a high correlation. That means that often a high happiness score is not related to high human freedom score.


#### 2.3.3 Non-Happiness Score Related Realtionships

**GDP and Family:**
```{r}
ggplot(data = dt_ds, aes(x = Economy..GDP.per.Capita., y = Family,)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "Weight of Family", x = "Weight of GDP per Capita")
```
As we saw in our analysis before, countries with a high happiness score also tend to put a high weight on GDP and Family and vice versa. So it makes sense that these two variables are positive correlated. because if a country has a high happiness score it likely also put a lot of weight on GDP and Family.

**GDP and Health & Life Expectancy:**
```{r}
ggplot(data = dt_ds, aes(x = Economy..GDP.per.Capita., y = Health..Life.Expectancy.)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "Weight of Health & Life Expectancy", x = "Weight of GDP per Capita")
```
The same observed for Family holds for Health & Life Expectancy, countries with a high happiness score also tend to put a high weight on GDP and Health & Life Expectancy and vice versa. So it makes sense that these two variables are positive correlated. If a country has a high happiness score it likely also put a lot of weight on GDP and Health & Life Expectancy for the calculation of their happiness score. 

**Freedom and pf_score:**
```{r}
ggplot(data = dt_ds, aes(x = Freedom, y = pf_score)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "personal freedom score", x = "Weight of Freedom")
```
The personal freedom score (pf_score) and the weight that was put to Freedom for the calculation of the happiness score show a positive correlation even though this correlation is not very strong. 
We can see that countries with a high personal freedom score often also put a lot of weight to freedom but this is not always the case.
This is quite interesting, indeed we would have expected that countries with a lot of freedom value this factor important for their happiness.

**GDP and ef_score:**
```{r}
ggplot(data = dt_ds, aes(x = Economy..GDP.per.Capita., y = ef_score)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "economic freedom score", x = "Weight of GDP per Capita")
```
The relationship is not very strong, but still clearly positive. Countries with more economical freedom give more importance to GDP regarding their happiness. So a country with more economic freedom will likely be more happy and vice versa, because it is probably associated with an high GDP weight, which is usually associated with higher happiness.

**ef_score and pf_score**
```{r}
ggplot(data = dt_ds, aes(x = pf_score, y = ef_score)) + 
  geom_point(aes(color = Region)) +
  geom_smooth(method = "lm") +
  labs(y = "economic freedom score", x = "personal freedom score")
```
Additionally, we can see that a higher personal freedom score also results in a higher economic freedom score. This shows that these two are related to each other and do not stand in contrast to one another.

**Conclusion:**
From this analysis we have two takeaways:
1. First correlation between two variables could seem to exist because countries with a high human freedom index tend to put more weight to certain variables (such as GDP, Health & Life Expectancy and Family).
2. Economic freedom score and personal freedom score do not show a strong correlation with GDP and Freedom.


## 3. Principal Component Analysis (PCA) (Adriana)


## 4. Cluster Analysis (Niklas)

#On cluster visualization:
Be very careful about the reliability of cluster visualization. It strongly depend on the amount of variance explained by the 2 first principal components (in this case it is less than 50% ). Nonetheless dividing the variables like previously mentioned, the visualization should be more accurate.

#On the interpretation fo the dendrogram:
Remember that the higher is the line that connect two points in the dendrogram, the more different they are. So an optimal number of cluster is the one where all the blocks are connected by very high lines. In your example 2 or 3 seem to be the most valid options.


#On using different methods
The perfect situation would be if both the wss plot (the one where elbow method is use) or the slihouette plot and the dendrogram of the hierarchical clustering suggest to use the same number of clusters. Put emphasis on this if that occurs. Moreover, if there is the possibility (the number of clusters is the same), compare how similar the results are with a table (just use table(labels of cluster1,labels of cluster2), if almost all the instances are divided in the same way (for example, almost all the ones that are in the first group of the first cluster are in the third group of second cluster, and this is recorded also for the other groups) then the reliability of the is higher because with different algorithms we arrived to similar results.



```{r include=FALSE}
library(factoextra)
library(cluster)
```

During our descriptive analysis we saw some patterns in our data. In the following analysis we will deepen that analysis with a cluster analysis. For that we will perform two different cluster analysis considering different variables.

**First Cluster Analysis**
The first one should consider only the columns of the first data set (and only the weights, not the happiness score or any other variable ). In this way countries will be grouped by their system of values, countries that consider the same things as important will be together.
After finding the clusters, it could be interesting to determine if a group is generally happier than the others. If that occurs it means that a particular system of value is more likely to lead happiness. On the contrary, if the scores are quite general, then there are different recipes for reaching happiness.

**Second Cluster Analysis**
The second one will take into account all the scores of the variables that were used to compute economic and personal freedom (these two will not be included). In this way countries will be grouped by their behavior regarding freedom. Countries in the same cluster will have similar politics regarding economics and social issues, or at least similar results (they record similar freedom scores).


### 4.1 Data Preparation
```{r}
clus1_dt <- dt[, c(7:12)]
clus2_dt <- dt[, c(17:28)]
rownames(clus1_dt) <- dt$countries
rownames(clust2_dt) <- dt$countries
```
**clus1_dt:** This data set only contains the weight of the variables used to calculate their happiness score (such as GDP, Freedom, etc.)
**clus2_dt:** This data set only contains the variables used to calculate ef_score and pf_score (such as pf_rol, ef_trade, etc.)

### 4.2 First Cluster Analysis

#### 4.2.1 K-Means Clustering 
We will start with k-means clustering. The method aim to partition the points into k groups such that the sum of squares from points to the assigned cluster centers is minimized.
We will start by visualizing the optimal number of clusters using the elbow method:
```{r}
clus1_dt_scaled <- scale(clus1_dt)
rownames(clus1_dt_scaled) = dt$countries
fviz_nbclust(clus1_dt_scaled, kmeans, method = "wss", nstart = 200) +
  geom_vline(xintercept = 3, linetype = 2)
```
The optimal number of clusters should be the point (or close to it) where the total within variance starts decreasing more slowly (the descendant is less steeper). We can see that this is the case here for a number of three clusters.

Let us do the cluster analysis in the following part.
```{r}
k = 3 # number of clusters
km_dt <- kmeans(clus1_dt_scaled, k, nstart = 200)
print(km_dt)
```
The summary shows us which countries are in which cluster. We are also able to compute the real average statistics for each country to better understand how each cluster looks like.

```{r}
aggregate(clus1_dt, by=list(cluster=km_dt$cluster), mean)
```
We can see a pattern between the three clusters. Except for Corruption and Generosity the weight drops for each cluster. This means that countries in cluster three have on average the highest weight on all six variables that were used to calculate their Happiness Score. In the first cluster these values are lower than from countries from the third cluster but higher for countries from the second cluster (except for Corruption and Generosity). The second cluster group has the lowest weights on average for most of their variables. This is not the case for Corruption and Generosity, here they score higher than group one but lower than group three
Knowing that this system of values is influencing their Happiness Score we will later have a look at the average Happiness score cluster and the countries cluster.

```{r}
fviz_cluster(km_dt, data = clus1_dt_scaled, 
             ellipse.type = "euclid",
             star.plot = T,
             repel = T,
             ggtheme = theme_minimal()
             )
```
The visualization is showing the way the countries are clustered. However, we have to be very careful about the reliability of cluster visualization. It strongly depend on the amount of variance explained by the 2 first principal components (in this case it is less than 50%).

#### 4.2.2 k-medoids clustering
We can also use k-medoids clustering. Each cluster is represented by a specific point in the cluster, which will be the most centrally located point in the cluster. This algorithm is more robust to noise and outliers. Using another clustering algorithm will be usefull so see if and how much our outcome of the clustering changes with another algorithm.

We will start by looking at the optimal number of clusters again.
```{r}
fviz_nbclust(clus1_dt_scaled, kmeans, method = "silhouette", nstart = 200)
```
As you can see, the optimal number of clusters is at 3, the same we got when we used the k-means algorithm. Now it is important for us to compare if the clusters we got a similar to the ones we compute here.

```{r}
k = 3 # number of clusters
pam_dt = pam(clus1_dt_scaled, k)
print(pam_dt)
```

```{r}
aggregate(clus1_dt, by=list(cluster=pam_dt$cluster), mean)
```
Notice, that the arrangement of the clusters in not the same, but if we look at the values of each cluster we get more or less the same picture as we did for our k-means algorithm. For example, we can see that one group (this case number 3) has on average the highest weight for all six categories.

#### 4.2.3 Hierachical Cluster
```{r}
dist.eucl <- dist(clus1_dt_scaled, method = "euclidean")
hc_dt <- hclust(dist.eucl)

fviz_dend(hc_dt, k = 3,
          cex = 0.3,
          color_labels_by_k = TRUE,
          rect = T)
```
Remember that the higher is the line that connect two points in the dendrogram, the more different they are. So an optimal number of cluster is the one where all the blocks are connected by very high lines. For our dendogram 3 seems to be a valid option. This again strengthens our findings of three different clusters we have in the data.


#### 4.2.4 Explaining and Comparing Clusters
```{r}
addmargins(table(pam_dt$clustering, km_dt$cluster))
```
We we look at the two clustering methods we choose (k-mediods and k-means) we can see that the clusters we obtained are more or less the same. Both clustering methods result in the same clusters except for a few observations. We will use the k-means clustering for further analysis.

For the next part we will have a look at the different clusters and their Happiness Score. We do not see that there are different recipes for achieving high happiness, but the higher the weight on the attributes the higher is the overall well-being of a country. 

```{r}
# data preparation
clus1_dt <- cbind(clus1_dt, Cluster = km_dt$cluster)
clus1_dt <- cbind(clus1_dt, Region = dt$Region)
clus1_dt <- cbind(clus1_dt, Happiness.Score = dt$Happiness.Score)

```
```{r}
clus1_dt[, mean(Happiness.Score), by = Cluster]
```
As one can see, the ranking for the clusters is the same as the ranking for their weight of their attributes. We can therefore see, that the more weight is put on the variables, the higher is their Happiness Score. Remember, that we also saw that countries from rich regions usually have a higher Happiness.Score on average. This means that they probably also have higher values for their variables.



### 4.3 Second Cluster Analysis
For the second Analysis we will follow the same procedure as for the first analysis. For questions regarding the procedure please have a look at the first cluster analysis.

#### 4.3.1 K-means Clustering
```{r}
clus2_dt_scaled <- scale(clus2_dt)
rownames(clus2_dt_scaled) = dt$countries

fviz_nbclust(clus2_dt_scaled, kmeans, method = "wss", nstart = 200) +
  geom_vline(xintercept = 2, linetype = 2)
```
We can see from the Graph that the optimal number of cluster lies around 2 - 3. We will choose two for the further analysis.

We then continue with the k-means clustering:
```{r}
k = 2 # number of clusters
km2_dt <- kmeans(clus2_dt_scaled, k, nstart = 200)
print(km2_dt)
```
```{r}
aggregate(clus2_dt, by=list(cluster=km2_dt$cluster), mean)
```
As you can see from our clustering we have two groups. Group number two performs better than group one in almost every single variable.

```{r}
fviz_cluster(km2_dt, data = clus2_dt_scaled, 
             ellipse.type = "euclid",
             star.plot = T,
             repel = T,
             ggtheme = theme_minimal()
             )
```
By looking at the visualization of the clusters we once again see that the dimension of both variables is not very high.

#### 4.3.2 K-Mediods Clustering

```{r}
fviz_nbclust(clus2_dt_scaled, kmeans, method = "silhouette", nstart = 200)
```
Using k-mediods we see that we get about the same number of optimal cluster as for the k-means clustering. This strengthens our position to choose two clusters.

```{r}
k = 2 # number of clusters
pam2_dt = pam(clus2_dt_scaled, k)
aggregate(clus2_dt, by=list(cluster=pam2_dt$cluster), mean)
```
As we can observe, we have a similar division of the variables for the two groups as we saw it for the k-means algorithm.

#### 4.3.3 Hierachical Clustering

```{r}
dist1.eucl <- dist(clus2_dt_scaled, method = "euclidean")
hc2_dt <- hclust(dist1.eucl)


fviz_dend(hc2_dt, k = 2,
          cex = 0.3,
          color_labels_by_k = TRUE,
          rect = T)
```
The hierarchical clustering supports our point to choose two clusters.

#### 4.3.4 Explaining and Comparing Clustersg
```{r}
addmargins(table(pam2_dt$clustering, km2_dt$cluster))
```
By comparing the two clustering methods we see that k-means and k-mediods choose the same cluster for almost every observation.

```{r}
# data preparation
clus2_dt <- cbind(clus2_dt, Cluster = km2_dt$cluster)
clus2_dt <- cbind(clus2_dt, Region = dt$Region)
clus2_dt <- cbind(clus2_dt, hf_score = dt$hf_score)

```
```{r}
clus2_dt[, mean(hf_score), by = Cluster]
```
We are also able to observe that higher scores for the variables that compute personal freedom and economic freedom result in a higher human freedom score and thus higher well being for the countries. 


## 5. Multidimensional Scaling (Adriana)


## 6. Perceptual Maps (Guglielmo)


## 7. Possible Extension (Guglielmo) (NEW HEADLINE NEEDED)
